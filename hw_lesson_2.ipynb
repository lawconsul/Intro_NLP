{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "from html.parser import unescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/radik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/radik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/radik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output_tweets'\n",
    "infile = open(filename,'rb')\n",
    "combine_df = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "\n",
    "Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "\n",
    "Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, texts_tweet_token = [], []\n",
    "for i, line in enumerate(combine_df['tweet_stemmed']):\n",
    "    texts_tweet_token.append(\" \".join(line))\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000, max_df=0.9)\n",
    "bag_of_words = count_vectorizer.fit_transform(texts_tweet_token)\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "df_cv_tweet_token = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "\n",
    "filename = 'df_cv_tweet_token'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df_cv_tweet_token,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, texts_tweet_lemmatized = [], []\n",
    "for i, line in enumerate(combine_df['tweet_lemmatized']):\n",
    "    texts_tweet_lemmatized.append(\" \".join(line))\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000, max_df=0.9)\n",
    "bag_of_words = count_vectorizer.fit_transform(texts_tweet_lemmatized)\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "df_cv_tweet_lemmatized = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "\n",
    "filename = 'df_cv_tweet_lemmatized'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df_cv_tweet_lemmatized,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). \n",
    "Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "\n",
    "Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "\n",
    "Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df=0.9)\n",
    "bag_of_words = tfidfVectorizer.fit_transform(texts_tweet_token)\n",
    "feature_names = tfidfVectorizer.get_feature_names()\n",
    "df_tfv_tweet_token = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "\n",
    "filename = 'df_tfv_tweet_token'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df_tfv_tweet_token,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df=0.9)\n",
    "bag_of_words = tfidfVectorizer.fit_transform(texts_tweet_lemmatized)\n",
    "feature_names = tfidfVectorizer.get_feature_names()\n",
    "df_tfv_tweet_lemmatized = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "\n",
    "filename = 'df_tfv_tweet_lemmatized'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df_tfv_tweet_lemmatized,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Натренируем gensim.models.Word2Vec модель на наших данных.\n",
    "\n",
    "Тренировать будем на токенизированных твитах combine_df['tweet_token']\n",
    "\n",
    "Установим следующие параметры: size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34.\n",
    "\n",
    "Используем функцию train() с параметром total_examples равным длине combine_df['tweet_token'], количество epochs установим 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "dataset = combine_df['tweet_token']\n",
    "data = [d for d in dataset]\n",
    "model = Word2Vec(data, size=200, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9142951, 11726520)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data, total_examples=model.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Давайте немного потестируем нашу модель Word2Vec и посмотрим, как она работает. \n",
    "\n",
    "Мы зададим слово positive = \"dinner\", и модель вытащит из корпуса наиболее похожие слова c помощью функции most_similar. \n",
    "\n",
    "То же самое попробуем со словом \"trump\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bihdaydinner', 0.563190221786499), ('cookout', 0.5501049757003784), ('shawarma', 0.5325543880462646)]\n"
     ]
    }
   ],
   "source": [
    "result = model.similar_by_word(\"dinner\", topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('donald', 0.5565332174301147), ('dumptrump', 0.5349440574645996), ('crony', 0.5135934948921204)]\n"
     ]
    }
   ],
   "source": [
    "result = model.similar_by_word(\"trump\", topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('donald', 0.5565332174301147), ('dumptrump', 0.5349440574645996), ('crony', 0.5135934948921204), ('conman', 0.5072427988052368), ('donaldtrump', 0.5065755844116211), ('trumptrain', 0.5065163969993591), ('commie', 0.5063521862030029), ('impeachment', 0.5044173002243042), ('fuhered', 0.5018693208694458), ('delegaterevolt', 0.5010116100311279)]\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['trump'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Из приведенных выше примеров мы видим, что наша модель word2vec хорошо справляется с поиском наиболее похожих слов для данного слова. Но как она это делает? Она изучила векторы для каждого уникального слова наших данных и использует косинусное сходство, чтобы найти наиболее похожие векторы (слова).\n",
    "\n",
    "Давайте проверим векторное представление любого слова из нашего корпуса, например \"food\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37801754\n"
     ]
    }
   ],
   "source": [
    "# определим схожесть между словами\n",
    "similarity = model.similarity('food', 'burger')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Поскольку наши данные содержат твиты, а не только слова, нам придется придумать способ использовать векторы слов из модели word2vec для создания векторного представления всего твита. Существует простое решение этой проблемы, мы можем просто взять среднее значение всех векторов слов, присутствующих в твите. Длина результирующего вектора будет одинаковой, то есть 200. Мы повторим тот же процесс для всех твитов в наших данных и получим их векторы. Теперь у нас есть 200 функций word2vec для наших данных.\n",
    "\n",
    "Необходимо создать вектор для каждого твита, взяв среднее значение векторов слов, присутствующих в твите. \n",
    "\n",
    "В цикле сделать:  vec += model_w2v[word].reshape((1, size))\n",
    "и поделить финальный вектор на количество слов в твите.\n",
    "\n",
    "На выходе должен получиться wordvec_df.shape = (49159, 200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(words):\n",
    "    size = 200\n",
    "    vec = np.zeros(size) \n",
    "    vec = vec.reshape(1, size)\n",
    "    norm = 0\n",
    "    for word in list(words):\n",
    "        try:\n",
    "            vec += model[word].reshape(1, size)\n",
    "            norm += 1\n",
    "        except KeyError:\n",
    "            norm += 0\n",
    "    if norm > 0:\n",
    "        vec = vec / norm\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_df = np.array(list(map(lambda s: get_vec(s), combine_df['tweet_token'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 200)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df = wordvec_df.reshape(49159, 200)\n",
    "wordvec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07023581,  0.20633666,  0.21011429, -0.12263244,  0.13387704,\n",
       "        0.11778077, -0.2788592 ,  0.17378253, -0.3868844 ,  0.30214327,\n",
       "       -0.04302077,  0.09093152,  0.09837542, -0.24681592, -0.17835215,\n",
       "       -0.06520925, -0.00440741,  0.14072396, -0.25762915, -0.09013469,\n",
       "        0.07741308,  0.01606197, -0.15052575,  0.29240547, -0.04468606,\n",
       "       -0.11161922, -0.22644533,  0.10272843,  0.14724459, -0.1788101 ,\n",
       "       -0.05939298,  0.13216337,  0.04035111,  0.19337628,  0.16649161,\n",
       "       -0.28145108,  0.00913418, -0.08060089, -0.02234066,  0.1194856 ,\n",
       "       -0.09446159, -0.01187711,  0.04454671,  0.01377404,  0.19575966,\n",
       "       -0.05676382,  0.04761382,  0.05132244, -0.25285748, -0.05233306,\n",
       "        0.01022195,  0.05693071,  0.22873623, -0.30330892,  0.01772877,\n",
       "       -0.17236061,  0.51334351,  0.10912371,  0.07961901, -0.13171821,\n",
       "        0.16055372,  0.18369018, -0.05771152, -0.02479237,  0.20080108,\n",
       "        0.18622582,  0.13149338, -0.10864402, -0.01280621, -0.0868403 ,\n",
       "       -0.0940839 ,  0.12698402, -0.18549165,  0.05575824,  0.15723385,\n",
       "        0.16965554,  0.2253074 , -0.06847524,  0.23951803,  0.05170425,\n",
       "       -0.26603859, -0.23708116,  0.06279747, -0.03865453,  0.01200077,\n",
       "       -0.18100346,  0.0345876 ,  0.01226541, -0.12025313, -0.27657784,\n",
       "        0.10302914, -0.26783352,  0.02602699,  0.10933749, -0.07411998,\n",
       "       -0.2173146 ,  0.07691261,  0.02000178,  0.11091642, -0.39940931,\n",
       "       -0.06764351,  0.20396252, -0.16903083,  0.40321854,  0.31690777,\n",
       "        0.21482833, -0.06751034, -0.16414608,  0.29248474,  0.01331106,\n",
       "        0.08715544, -0.04544467,  0.03603333,  0.17856814, -0.04849685,\n",
       "       -0.19043573, -0.05084179,  0.04251182,  0.14051978,  0.50697047,\n",
       "       -0.13182928,  0.01991681, -0.2091684 ,  0.08058537, -0.13417033,\n",
       "        0.06238951, -0.11775318, -0.0340476 , -0.02160674,  0.11904559,\n",
       "       -0.16003603, -0.09425152,  0.16313282,  0.15617515, -0.04923866,\n",
       "       -0.01682727, -0.21119955,  0.17836725, -0.25499943,  0.08820029,\n",
       "       -0.12793048, -0.13014363,  0.37744242,  0.05943309, -0.19523238,\n",
       "       -0.04242637,  0.1374462 , -0.05518363, -0.02055386,  0.05851652,\n",
       "       -0.19925017,  0.27126582, -0.07606736, -0.50445629,  0.19730639,\n",
       "        0.25751944, -0.05722514,  0.36427754,  0.08685098, -0.14380008,\n",
       "        0.02248965,  0.17972533, -0.12154152, -0.09325524, -0.05002691,\n",
       "       -0.03064225, -0.09478495,  0.10833514, -0.19116277, -0.03158587,\n",
       "       -0.11423651,  0.12856122, -0.06525867, -0.14667924, -0.19009055,\n",
       "       -0.19776742,  0.34347822, -0.05006377,  0.19622004, -0.18701974,\n",
       "       -0.00230876,  0.10386811,  0.02591831,  0.01824093, -0.15066686,\n",
       "       -0.05865785, -0.02955015,  0.06839651,  0.14403638, -0.28571655,\n",
       "       -0.01064376, -0.01058079, -0.32654158, -0.0203883 , -0.27618533,\n",
       "       -0.0201236 , -0.14694477,  0.00270619,  0.13948618,  0.05564229])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "На выходе должен получиться wordvec_df.shape = (49159, 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple chat-bot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymorphy2\n",
    "# ! pip install stop_words\n",
    "# !pip install annoy\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b88dfe6ff54862bfad7773c58d72e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "#Small preprocess of the answers\n",
    "\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"prepared_answers.txt\", \"w\") as fout:\n",
    "    with open(\"Otvety.txt\", \"r\") as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af12676017e847f0909e6dca69aa6c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "# Preprocess for models fitting\n",
    "\n",
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"Otvety.txt\", \"r\") as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вопрос', 'тдв', 'отдыхать', 'лично', 'советовать', 'завести']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, size=50, min_count=1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=sentences, size=50, min_count=1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5e21abb43b472ca5a43da2a410bee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(50 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(50 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"prepared_answers.txt\", \"r\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_w2v = np.zeros(50)\n",
    "        vector_ft = np.zeros(50)\n",
    "        for word in question:\n",
    "            if word in modelW2V:\n",
    "                vector_w2v += modelW2V[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT:\n",
    "                vector_ft += modelFT[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 100000:\n",
    "            break\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1577, 2139, 4363]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index.get_nns_by_vector(np.zeros(50), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(50)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"когда сменится президент\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n',\n",
       " 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n',\n",
       " 'Твой.. \\n']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, modelW2V, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Следите за новостями в Украине. Как только там начнётся - считайте, что караван верблюдов уже вышел.. . Ждите, когда он прийдёт к вам.. . А лучше - скупайте баксы.... \\n',\n",
       " 'Поторопился..... \\n',\n",
       " 'Казалось бы, те усилия, что были приложены державами-победительницами в 1 Мировой войне для создания нового миропорядка, должны были обеспечить мир и благоденствие на многие годы. <br>Благие пожелания.. . <br>Рухнула Австро-Венгерская империя - \"лоскутная империя\", как её справедливо называли. На её обломках возникли как жизнеспособные государственные образования : Австрия, Венгрия, Чехословакия, Польша, так и новое \"лоскутное государство\" - Югославия. <br>Если щедрая раздача мандатов на управление бывшими германскими колониями в Африке и на Тихом океане не принесла эксцессов, то бывшие турецкие владения на Ближнем Востоке принесли бесконечную головную боль их новым владельцам. <br>Едва были заключены Вашингтонские соглашения об ограничении морских вооружений, как Япония, Германия и Италия немедленно стали искать обходные пути для нарушения этих соглашений. <br>Наконец, вялость и нерешительность ведущих мировых держав при переводе экономики с военных рельсов на гражданские, немало способствовали возникновению Великой депрессии. <br>Экономические санкции, возложенные на Центральные державы ( прежде всего на Германию) оказались не справедливой карой за содеянное, а удавкой, способствовавшей возникновению фашизма и национал-социализма. <br>И СССР внёс свою лепту в дестабилизацию политических режимов Европы с помощью Коминтерна. <br>Таким образом, Первая Мировая война не разрешила накопленных проблем - она их только приумножила.. \\n']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, modelFT, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(size, question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(size)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 3)\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHECK(size,min_count,window):\n",
    "    modelW2V = Word2Vec(sentences=sentences, size=size, min_count=min_count, window=window)\n",
    "    modelFT = FastText(sentences=sentences, size=size, min_count=min_count, window=window)\n",
    "\n",
    "    w2v_index = annoy.AnnoyIndex(size ,'angular')\n",
    "    ft_index = annoy.AnnoyIndex(size ,'angular')\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"prepared_answers.txt\", \"r\") as f:\n",
    "        for line in tqdm_notebook(f):\n",
    "            n_w2v = 0\n",
    "            n_ft = 0\n",
    "            spls = line.split(\"\\t\")\n",
    "            index_map[counter] = spls[1]\n",
    "            question = preprocess_txt(spls[0])\n",
    "\n",
    "            vector_w2v = np.zeros(size)\n",
    "            vector_ft = np.zeros(size)\n",
    "            for word in question:\n",
    "                if word in modelW2V:\n",
    "                    vector_w2v += modelW2V[word]\n",
    "                    n_w2v += 1\n",
    "                if word in modelFT:\n",
    "                    vector_ft += modelFT[word]\n",
    "                    n_ft += 1\n",
    "            if n_w2v > 0:\n",
    "                vector_w2v = vector_w2v / n_w2v\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "            w2v_index.add_item(counter, vector_w2v)\n",
    "            ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if counter > 100000:\n",
    "                break\n",
    "\n",
    "    w2v_index.build(10)\n",
    "    ft_index.build(10)\n",
    "\n",
    "    w2v_index.get_nns_by_vector(np.zeros(size), 3)\n",
    "    \n",
    "    print(f\"size={size}, min_count={min_count}, window={window}\")\n",
    "    print(get_response(size, TEXT, w2v_index, modelW2V, index_map))\n",
    "    print(get_response(size, TEXT, ft_index, modelFT, index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09adfe6becd04d14962c945240daef68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=100, min_count=1, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Твой.. \\n']\n",
      "['Следите за новостями в Украине. Как только там начнётся - считайте, что караван верблюдов уже вышел.. . Ждите, когда он прийдёт к вам.. . А лучше - скупайте баксы.... \\n', 'БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Отели Хилтон, по всему миру. <br>К настоящему времени Hilton представляет собой огромную корпорацию со штаб–квартирой в Беверли- Хилз (Калифорния, США) , которая в свою очередь состоит из восьми гостиничных цепей (Conrad Hotels, Doubletree, Embassy Suites Hotels, Hampton Inn, Hampton Inn and Suites, Hilton Hotels, Hilton Garden inn, Homewood Suites by Hilton), имеющих собственные стандарты обслуживания. В собственности и под управлением корпорации находится свыше 2,5 тыс. клубов и центров отдыха, отелей (свыше 500 на 148 000 номеров) на территории 75 стран пяти континентов и около 2 тыс. игорных заведений и букмекерских контор, располагающих более чем 600-тысячной клиентурой в 160 странах мира. Количество сотрудников — свыше 70 тыс. человек. Финансовый оборот — около 9 млрд. фунтов стерлингов.. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=100,min_count=1,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb7a2ac01284b5f81459ec8bb7a27ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=100, min_count=1, window=1\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Постоянно тупить). \\n']\n",
      "['Отели Хилтон, по всему миру. <br>К настоящему времени Hilton представляет собой огромную корпорацию со штаб–квартирой в Беверли- Хилз (Калифорния, США) , которая в свою очередь состоит из восьми гостиничных цепей (Conrad Hotels, Doubletree, Embassy Suites Hotels, Hampton Inn, Hampton Inn and Suites, Hilton Hotels, Hilton Garden inn, Homewood Suites by Hilton), имеющих собственные стандарты обслуживания. В собственности и под управлением корпорации находится свыше 2,5 тыс. клубов и центров отдыха, отелей (свыше 500 на 148 000 номеров) на территории 75 стран пяти континентов и около 2 тыс. игорных заведений и букмекерских контор, располагающих более чем 600-тысячной клиентурой в 160 странах мира. Количество сотрудников — свыше 70 тыс. человек. Финансовый оборот — около 9 млрд. фунтов стерлингов.. \\n', 'ага. ты еще напиши в каком городе ездишь.... и номер машины!. \\n', 'Из документов мы можем почерпнуть свидетельства рождения детей с удивительными способностями ещё во времена зарождения христианства. <br><br>Другое дело, - и тут уже нельзя не согласиться, - что в последние десятилетия это явление приобрело крупномасштабный характер, и, если верить статистике, каждый десятый ребёнок, рождающийся сегодня на Земле, - Индиго. <br><br>Так кто же такие эти удивительные создания - результат эволюции человеческого организма или генетический продукт инопланетного разума? Ответить на этот вопрос пытаются учёные всего мира, высказывая по этому поводу различного рода гипотезы, - одна экзотичнее другой. <br><br>Но факт остаётся фактом - дети Индиго появляются на свет с заставляющим задумываться постоянством и со всё увеличивающейся прогрессией. <br><br>На первый взгляд, между ними нет ничего общего. Они могут родиться в Букингемском дворце и в трущобах Гарлема. Их родителями могут быть как наркоманы, так и преуспевающие бизнесмены. Их объединяет одно - аура цвета индиго и судьба, которая может изменить будущее человечества. <br><br>Из глубины веков<br><br>Прослеживая историю человеческой цивилизации от отблесков пещерных костров до пламени дюз ракетных кораблей, можно отметить наверняка одно: прогресс и развитие, её (цивилизацию) сопровождавшие, явились результатом титанического труда отдельно взятых личностей, своей мыслью всколыхнувших спокойное течение жизни. Пифагор и Аристотель, Авиценна и да Винчи, Коперник и Декарт, Ломоносов и Эйнштейн - люди, которые внесли в историю науки несравненно больше, чем тысячи поколений обывателей, сгинувших во тьме веков, чьи имена мы никогда не узнаем, потому как они нам безразличны. Разве в раннем возрасте их нельзя было назвать детьми Индиго? Отдельные неканонические христианские источники утверждают, что у Иисуса Христа аура так же была ультрамаринового цвета. Мы не имеем в виду лидеров с сильной волей, - таких, как Чингисхан, Александр Македонский или Робеспьер, изменявших судьбы миллионов, создающих империи и совершающих революции. У них на наш взгляд, другие способности и другая судьба. Хотя, как знать? <br><br>Исторических примеров людей с удивительными способностями хватает. В своей книге \"100 великих тайн\" А. Ю. Низовский и Н. Н. Непомнящий упоминают о человеке по имени Боттино Этьен из Шамптосо, или, как его ещё называли, \"человек-радар из Порт-Луи\", который прославился тем, что мог угадывать появление кораблей из-за горизонта.. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=100,min_count=1,window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618a867d30d14f4f90a211a16f16b7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=1, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'смотря на какую должность. \\n']\n",
      "['Следите за новостями в Украине. Как только там начнётся - считайте, что караван верблюдов уже вышел.. . Ждите, когда он прийдёт к вам.. . А лучше - скупайте баксы.... \\n', 'Отели Хилтон, по всему миру. <br>К настоящему времени Hilton представляет собой огромную корпорацию со штаб–квартирой в Беверли- Хилз (Калифорния, США) , которая в свою очередь состоит из восьми гостиничных цепей (Conrad Hotels, Doubletree, Embassy Suites Hotels, Hampton Inn, Hampton Inn and Suites, Hilton Hotels, Hilton Garden inn, Homewood Suites by Hilton), имеющих собственные стандарты обслуживания. В собственности и под управлением корпорации находится свыше 2,5 тыс. клубов и центров отдыха, отелей (свыше 500 на 148 000 номеров) на территории 75 стран пяти континентов и около 2 тыс. игорных заведений и букмекерских контор, располагающих более чем 600-тысячной клиентурой в 160 странах мира. Количество сотрудников — свыше 70 тыс. человек. Финансовый оборот — около 9 млрд. фунтов стерлингов.. \\n', 'Казалось бы, те усилия, что были приложены державами-победительницами в 1 Мировой войне для создания нового миропорядка, должны были обеспечить мир и благоденствие на многие годы. <br>Благие пожелания.. . <br>Рухнула Австро-Венгерская империя - \"лоскутная империя\", как её справедливо называли. На её обломках возникли как жизнеспособные государственные образования : Австрия, Венгрия, Чехословакия, Польша, так и новое \"лоскутное государство\" - Югославия. <br>Если щедрая раздача мандатов на управление бывшими германскими колониями в Африке и на Тихом океане не принесла эксцессов, то бывшие турецкие владения на Ближнем Востоке принесли бесконечную головную боль их новым владельцам. <br>Едва были заключены Вашингтонские соглашения об ограничении морских вооружений, как Япония, Германия и Италия немедленно стали искать обходные пути для нарушения этих соглашений. <br>Наконец, вялость и нерешительность ведущих мировых держав при переводе экономики с военных рельсов на гражданские, немало способствовали возникновению Великой депрессии. <br>Экономические санкции, возложенные на Центральные державы ( прежде всего на Германию) оказались не справедливой карой за содеянное, а удавкой, способствовавшей возникновению фашизма и национал-социализма. <br>И СССР внёс свою лепту в дестабилизацию политических режимов Европы с помощью Коминтерна. <br>Таким образом, Первая Мировая война не разрешила накопленных проблем - она их только приумножила.. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=1,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c1040131944dd7909ab898bad7a4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=2, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Потому что большинство считали что это фарс чтобы подорвать репутацию новой власти Украины. Поэтому ему просто не сообщили место и день регистрации. И конечно потому что он был бы серьезным конкурентом на пост президента, его бы поддержала практически вся молодёжь. Но теперь он собирается стать мэром города Одессы, и в него есть все шансы. Дарт Вейдер выступает как интернет партия Украины, и ничего никому не обещает.. \\n']\n",
      "['БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Казалось бы, те усилия, что были приложены державами-победительницами в 1 Мировой войне для создания нового миропорядка, должны были обеспечить мир и благоденствие на многие годы. <br>Благие пожелания.. . <br>Рухнула Австро-Венгерская империя - \"лоскутная империя\", как её справедливо называли. На её обломках возникли как жизнеспособные государственные образования : Австрия, Венгрия, Чехословакия, Польша, так и новое \"лоскутное государство\" - Югославия. <br>Если щедрая раздача мандатов на управление бывшими германскими колониями в Африке и на Тихом океане не принесла эксцессов, то бывшие турецкие владения на Ближнем Востоке принесли бесконечную головную боль их новым владельцам. <br>Едва были заключены Вашингтонские соглашения об ограничении морских вооружений, как Япония, Германия и Италия немедленно стали искать обходные пути для нарушения этих соглашений. <br>Наконец, вялость и нерешительность ведущих мировых держав при переводе экономики с военных рельсов на гражданские, немало способствовали возникновению Великой депрессии. <br>Экономические санкции, возложенные на Центральные державы ( прежде всего на Германию) оказались не справедливой карой за содеянное, а удавкой, способствовавшей возникновению фашизма и национал-социализма. <br>И СССР внёс свою лепту в дестабилизацию политических режимов Европы с помощью Коминтерна. <br>Таким образом, Первая Мировая война не разрешила накопленных проблем - она их только приумножила.. \\n', 'но не всегда в Иерусалиме была одна религия, во время крестовых походов сей град бывал захвачен рыцарями.. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=2,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55a23a8b2654e51bafa6166e32918e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=3, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Твой.. \\n']\n",
      "['БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Жиды запретили обязательную государственную идеологию, но зато рекламируют и обязательно внедряют в жизнь граждан свою частную идеологию - ПОТРЕБЛЕНИЯ любой ценой, с отрицанием морали и совести, по Шекспиру - сделал дельце - заметай следы. Или кто смел, тот и съел. Поэтому страна добилась 200 евреев- жидов, правящих Россией.... \\n', 'но не всегда в Иерусалиме была одна религия, во время крестовых походов сей град бывал захвачен рыцарями.. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=3,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d1f9a61fd24e2ea77691e49f7a9d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=1, window=10\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', '<p>Президент Турецкой Республики (тур. Türkiye Cumhuriyeti Cumhurbaşkanı) является главой государства Турецкой Республики.</p> <p>Являясь в основном церемониальной должностью, президент представляет Турецкую Республику и символизирует единство турецкой нации. При этом его важнейшими функциями является обеспечение исполнения Конституции и гармоничного взаимодействия других государственных органов. Статьи от 101 до 106 Конституции устанавливает требования к кандидатам, порядок избрания, обязанности и ответственность президента.</p> <p>После подписания 24 июля 1923 года Лозаннского мирного договора и международного признания Великого Национального Собрания Турции, 29 октября 1923 года было провозглашено создание Турецкой Республики, являвшейся преемницей Османской империи; в тот же день первым президентом был избран председатель Великого Национального собрания Турции Мустафа Кемаль-паша. 3 марта 1924 года был окончательно ликвидирован Османский халифат.</p> <p>До внесения в 2007 году поправки в Конституцию, президент избирался членами турецкого парламента. Согласно поправке он избираются гражданами путём прямого голосования. Для того, чтобы стать президентом Турции, кандидат должен иметь законченное высшее образование и быть не моложе сорока лет. Избранный президент должен прекратить свои отношения, если таковые имеются, с его политической партией, и членство в Великом Национальном собрании Турции.</p> <p>Президент имеет возможность активно участвовать в законодательной деятельности: направлять принятые парламентом законопроекты на повторное рассмотрение, вносить законопроекты на обсуждение, инициировать референдум по изменению Конституции, издавать указы (которые в установленных Конституцией случаях должны быть подтверждены премьер-министром страны и соответствующим министром).</p> <p>Президент может быть отрешён от должности за государственную измену по предложению не менее одной трети от общего числа членов парламента, и по решению не менее трех четвертей от их общего числа членов.</p>   <h2>Диаграмма пребывания в должности</h2> <h2>Список президентов Турецкой республики</h2> <h2>См. также</h2> <ul> <li>Премьер-министр Турции</li> </ul> <h2>Ссылки</h2> <ul> <li>Список руководителей Турции \\xa0(англ.)</li> </ul> <h2>Примечания</h2>. \\n']\n",
      "['Следите за новостями в Украине. Как только там начнётся - считайте, что караван верблюдов уже вышел.. . Ждите, когда он прийдёт к вам.. . А лучше - скупайте баксы.... \\n', 'БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Казалось бы, те усилия, что были приложены державами-победительницами в 1 Мировой войне для создания нового миропорядка, должны были обеспечить мир и благоденствие на многие годы. <br>Благие пожелания.. . <br>Рухнула Австро-Венгерская империя - \"лоскутная империя\", как её справедливо называли. На её обломках возникли как жизнеспособные государственные образования : Австрия, Венгрия, Чехословакия, Польша, так и новое \"лоскутное государство\" - Югославия. <br>Если щедрая раздача мандатов на управление бывшими германскими колониями в Африке и на Тихом океане не принесла эксцессов, то бывшие турецкие владения на Ближнем Востоке принесли бесконечную головную боль их новым владельцам. <br>Едва были заключены Вашингтонские соглашения об ограничении морских вооружений, как Япония, Германия и Италия немедленно стали искать обходные пути для нарушения этих соглашений. <br>Наконец, вялость и нерешительность ведущих мировых держав при переводе экономики с военных рельсов на гражданские, немало способствовали возникновению Великой депрессии. <br>Экономические санкции, возложенные на Центральные державы ( прежде всего на Германию) оказались не справедливой карой за содеянное, а удавкой, способствовавшей возникновению фашизма и национал-социализма. <br>И СССР внёс свою лепту в дестабилизацию политических режимов Европы с помощью Коминтерна. <br>Таким образом, Первая Мировая война не разрешила накопленных проблем - она их только приумножила.. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=1,window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7519d68d4662466f8349a3bf0fa2052b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=2, window=10\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', '<p>Президент Турецкой Республики (тур. Türkiye Cumhuriyeti Cumhurbaşkanı) является главой государства Турецкой Республики.</p> <p>Являясь в основном церемониальной должностью, президент представляет Турецкую Республику и символизирует единство турецкой нации. При этом его важнейшими функциями является обеспечение исполнения Конституции и гармоничного взаимодействия других государственных органов. Статьи от 101 до 106 Конституции устанавливает требования к кандидатам, порядок избрания, обязанности и ответственность президента.</p> <p>После подписания 24 июля 1923 года Лозаннского мирного договора и международного признания Великого Национального Собрания Турции, 29 октября 1923 года было провозглашено создание Турецкой Республики, являвшейся преемницей Османской империи; в тот же день первым президентом был избран председатель Великого Национального собрания Турции Мустафа Кемаль-паша. 3 марта 1924 года был окончательно ликвидирован Османский халифат.</p> <p>До внесения в 2007 году поправки в Конституцию, президент избирался членами турецкого парламента. Согласно поправке он избираются гражданами путём прямого голосования. Для того, чтобы стать президентом Турции, кандидат должен иметь законченное высшее образование и быть не моложе сорока лет. Избранный президент должен прекратить свои отношения, если таковые имеются, с его политической партией, и членство в Великом Национальном собрании Турции.</p> <p>Президент имеет возможность активно участвовать в законодательной деятельности: направлять принятые парламентом законопроекты на повторное рассмотрение, вносить законопроекты на обсуждение, инициировать референдум по изменению Конституции, издавать указы (которые в установленных Конституцией случаях должны быть подтверждены премьер-министром страны и соответствующим министром).</p> <p>Президент может быть отрешён от должности за государственную измену по предложению не менее одной трети от общего числа членов парламента, и по решению не менее трех четвертей от их общего числа членов.</p>   <h2>Диаграмма пребывания в должности</h2> <h2>Список президентов Турецкой республики</h2> <h2>См. также</h2> <ul> <li>Премьер-министр Турции</li> </ul> <h2>Ссылки</h2> <ul> <li>Список руководителей Турции \\xa0(англ.)</li> </ul> <h2>Примечания</h2>. \\n']\n",
      "['БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Вообще-то они не имеют права..... \\n', 'я тока стакан захвачу. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=2,window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be9253ac33b4d188cfce3b44f4db938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=2, window=20\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Это тост.... \\n']\n",
      "['двумя руками - за. \\n', 'Ну конечтно это мой любимый фильм. Но все равно кажется что продолжение есть продолжение. Никто не сыграет так как сыграл А. Мягков. Верно?. \\n', 'БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=2,window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae41c56637a7485cbcd8245bea87449b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=50, min_count=2, window=20\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Твой.. \\n']\n",
      "['БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Я и так успешна и независима. А стать участником - не хочу.. \\n', 'Гарри женился на Невиле Долгопупсе. Дамблдор на Волан-де морте)). \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=50,min_count=2,window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb49475888ab445a9e84e2b3a7b0d1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=10, min_count=1, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', '<p>Президент Турецкой Республики (тур. Türkiye Cumhuriyeti Cumhurbaşkanı) является главой государства Турецкой Республики.</p> <p>Являясь в основном церемониальной должностью, президент представляет Турецкую Республику и символизирует единство турецкой нации. При этом его важнейшими функциями является обеспечение исполнения Конституции и гармоничного взаимодействия других государственных органов. Статьи от 101 до 106 Конституции устанавливает требования к кандидатам, порядок избрания, обязанности и ответственность президента.</p> <p>После подписания 24 июля 1923 года Лозаннского мирного договора и международного признания Великого Национального Собрания Турции, 29 октября 1923 года было провозглашено создание Турецкой Республики, являвшейся преемницей Османской империи; в тот же день первым президентом был избран председатель Великого Национального собрания Турции Мустафа Кемаль-паша. 3 марта 1924 года был окончательно ликвидирован Османский халифат.</p> <p>До внесения в 2007 году поправки в Конституцию, президент избирался членами турецкого парламента. Согласно поправке он избираются гражданами путём прямого голосования. Для того, чтобы стать президентом Турции, кандидат должен иметь законченное высшее образование и быть не моложе сорока лет. Избранный президент должен прекратить свои отношения, если таковые имеются, с его политической партией, и членство в Великом Национальном собрании Турции.</p> <p>Президент имеет возможность активно участвовать в законодательной деятельности: направлять принятые парламентом законопроекты на повторное рассмотрение, вносить законопроекты на обсуждение, инициировать референдум по изменению Конституции, издавать указы (которые в установленных Конституцией случаях должны быть подтверждены премьер-министром страны и соответствующим министром).</p> <p>Президент может быть отрешён от должности за государственную измену по предложению не менее одной трети от общего числа членов парламента, и по решению не менее трех четвертей от их общего числа членов.</p>   <h2>Диаграмма пребывания в должности</h2> <h2>Список президентов Турецкой республики</h2> <h2>См. также</h2> <ul> <li>Премьер-министр Турции</li> </ul> <h2>Ссылки</h2> <ul> <li>Список руководителей Турции \\xa0(англ.)</li> </ul> <h2>Примечания</h2>. \\n']\n",
      "['Отели Хилтон, по всему миру. <br>К настоящему времени Hilton представляет собой огромную корпорацию со штаб–квартирой в Беверли- Хилз (Калифорния, США) , которая в свою очередь состоит из восьми гостиничных цепей (Conrad Hotels, Doubletree, Embassy Suites Hotels, Hampton Inn, Hampton Inn and Suites, Hilton Hotels, Hilton Garden inn, Homewood Suites by Hilton), имеющих собственные стандарты обслуживания. В собственности и под управлением корпорации находится свыше 2,5 тыс. клубов и центров отдыха, отелей (свыше 500 на 148 000 номеров) на территории 75 стран пяти континентов и около 2 тыс. игорных заведений и букмекерских контор, располагающих более чем 600-тысячной клиентурой в 160 странах мира. Количество сотрудников — свыше 70 тыс. человек. Финансовый оборот — около 9 млрд. фунтов стерлингов.. \\n', 'Следите за новостями в Украине. Как только там начнётся - считайте, что караван верблюдов уже вышел.. . Ждите, когда он прийдёт к вам.. . А лучше - скупайте баксы.... \\n', 'кстати санкция лишения в/у имеется за передачу Т/С водителю не имеющему в/у и находящемся в Н/С. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=10,min_count=1,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f468aa5663ab4601b1604a580279d2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=10, min_count=1, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', 'Они еще и дебилы-тунеядцы-вредители..... \\n']\n",
      "['Жиды запретили обязательную государственную идеологию, но зато рекламируют и обязательно внедряют в жизнь граждан свою частную идеологию - ПОТРЕБЛЕНИЯ любой ценой, с отрицанием морали и совести, по Шекспиру - сделал дельце - заметай следы. Или кто смел, тот и съел. Поэтому страна добилась 200 евреев- жидов, правящих Россией.... \\n', 'Следите за новостями в Украине. Как только там начнётся - считайте, что караван верблюдов уже вышел.. . Ждите, когда он прийдёт к вам.. . А лучше - скупайте баксы.... \\n', 'Опять майдан!. \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=10,min_count=1,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb6f35e50d84cafa8389320ce6b408b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=10, min_count=2, window=5\n",
      "['Скорее всего я или люди из моего окружения.Так что знакомтесь пока есть время и вожможность. \\n', 'Вам, мадам, к психиатру нужно. И как можно скорее.... \\n', '<p> Университеты, театр,библиотеки,музеи, относительно независимая пресса - эпоха Просвещения-вторая половина 18 века </p>. \\n']\n",
      "['БОРИСОВ <br>БОРИН БОРИСЕВИЧ БОРИСЕНКО БОРИСИХИН БОРИСКИН БОРИСОВ БОРИСОВЕЦ БОРИСОВИЧ БОРИСЯК БОРИЧЕВ БОРИЩЕВ БОРИЩЕНКО БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ БОРИСЕНОК БОРИСЕНКОВ БОРИСОВЕЦ БОРИСЫЧЕВ <br> <br>Фамилия образована из отчества от крестильного имени Борис и его производных форм - Боря, Борище. По поводу объяснения самого имени нет единого мнения, в словарях предлагается объяснение из рус. и болг. - борец или как сокращенная форма славянского имени Борислав. Борисовец. От именвания жителя г. Борисов. Борисихин. может быть от Борисиха, жена Бориса.<br>. \\n', 'Видео должно принадлежать только тебе, и не вставляй в видео какие нибудь песни музыку, все только свое, и кстати видео это удали, а то забанить могут. Я тут недавно 2 недели в бане сидел за нарушение авторских прав.. \\n', 'Футурама - тема.. . да.... \\n']\n"
     ]
    }
   ],
   "source": [
    "CHECK(size=10,min_count=2,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экспортируем лучшие модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'modelW2V_best'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(modelW2V,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'modelFT_best'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(modelFT,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
